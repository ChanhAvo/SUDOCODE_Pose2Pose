{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiZUrnpZt28z",
        "outputId": "ba113210-9e81-44d9-80b0-8f3503e6f8c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYi1AvXrrnE1",
        "outputId": "adff45f2-fd5d-40d6-cb6f-8a1fab00d9bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: patool in /usr/local/lib/python3.12/dist-packages (4.0.2)\n",
            "Requirement already satisfied: underthesea in /usr/local/lib/python3.12/dist-packages (8.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.12/dist-packages (from underthesea) (8.3.0)\n",
            "Requirement already satisfied: python-crfsuite>=0.9.6 in /usr/local/lib/python3.12/dist-packages (from underthesea) (0.9.11)\n",
            "Requirement already satisfied: nltk>=3.8 in /usr/local/lib/python3.12/dist-packages (from underthesea) (3.9.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from underthesea) (1.5.2)\n",
            "Requirement already satisfied: underthesea_core==1.0.5 in /usr/local/lib/python3.12/dist-packages (from underthesea) (1.0.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers sentence-transformers faiss-cpu patool underthesea"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HhZ0qfZIvPzJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import patoolib\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import List, Dict, Tuple\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "from underthesea import word_tokenize\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBloA0LqYWK7"
      },
      "outputs": [],
      "source": [
        "base_dir = \"/content/drive/MyDrive/VSL\"\n",
        "os.makedirs(f\"{base_dir}/data/raw\", exist_ok=True)\n",
        "os.makedirs(f\"{base_dir}/data/videos\", exist_ok=True)\n",
        "os.makedirs(f\"{base_dir}/data/embeddings\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlrKT4Fjryu9",
        "outputId": "91b256f3-8e19-4e3a-9700-c5049f9b4fb8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO patool: Extracting /content/drive/MyDrive/VSL/data/raw/VIDEO.rar ...\n",
            "INFO:patool:Extracting /content/drive/MyDrive/VSL/data/raw/VIDEO.rar ...\n",
            "INFO patool: running /usr/bin/unrar x -kb -or -- /content/drive/MyDrive/VSL/data/raw/VIDEO.rar\n",
            "INFO:patool:running /usr/bin/unrar x -kb -or -- /content/drive/MyDrive/VSL/data/raw/VIDEO.rar\n",
            "INFO patool: ... /content/drive/MyDrive/VSL/data/raw/VIDEO.rar extracted to `/content/drive/MyDrive/VSL/data/videos'.\n",
            "INFO:patool:... /content/drive/MyDrive/VSL/data/raw/VIDEO.rar extracted to `/content/drive/MyDrive/VSL/data/videos'.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/VSL/data/videos'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#extract videos from rar file\n",
        "rar_path = f\"{base_dir}/data/raw/VIDEO.rar\"\n",
        "output_dir = f\"{base_dir}/data/videos\"\n",
        "patoolib.extract_archive(rar_path, outdir=output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "e0A09jbzW4cp"
      },
      "outputs": [],
      "source": [
        "#prepare data\n",
        "class VietnameseSignLanguageData:\n",
        "    def __init__(self, json_path: str):\n",
        "        self.json_path = json_path\n",
        "        self.data = None\n",
        "        self.df = None\n",
        "\n",
        "    def load_data(self):\n",
        "        with open(self.json_path, 'r', encoding='utf-8') as f:\n",
        "            self.data = json.load(f)\n",
        "\n",
        "        self.df = pd.DataFrame(self.data['data'])\n",
        "        print(f\"Loaded {len(self.df)} sign language entries\")\n",
        "        return self.df\n",
        "\n",
        "    def preprocess_text(self, text: str) -> str:\n",
        "        if not text or pd.isna(text):\n",
        "          return \"\"\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[^\\w\\s]', '', text)\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "        return text\n",
        "\n",
        "    def create_searchable_text(self, row: pd.Series) -> str:\n",
        "        parts = [\n",
        "            row['word'],\n",
        "            row.get('_word', ''),\n",
        "            row.get('description', ''),\n",
        "            row.get('tl', '')\n",
        "        ]\n",
        "        return \" \".join([str(p) for p in parts if p and not pd.isna(p)])\n",
        "\n",
        "    def prepare_data(self):\n",
        "        self.df['word_normalized'] = self.df['word'].apply(self.preprocess_text)\n",
        "        self.df['description_normalized'] = self.df['description'].apply(self.preprocess_text)\n",
        "        self.df['searchable_text'] = self.df.apply(self.create_searchable_text, axis=1)\n",
        "        self.df['searchable_text_normalized'] = self.df['searchable_text'].apply(self.preprocess_text)\n",
        "        print(\"Data preprocessing complete\")\n",
        "        return self.df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6GH4E43NXLCX"
      },
      "outputs": [],
      "source": [
        "#embedding model\n",
        "class Embedder:\n",
        "    def __init__(self, model_name: str = \"dangvantuan/vietnamese-embedding\"):\n",
        "        print(f\"Loading SentenceTransformer model: {model_name}\")\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "        print(\"Model loaded successfully.\")\n",
        "\n",
        "    def embed_text(self, text: str) -> np.ndarray:\n",
        "        if not text:\n",
        "            return np.zeros(self.model.get_sentence_embedding_dimension())\n",
        "        embedding = self.model.encode(text, convert_to_numpy=True, normalize_embeddings=True)\n",
        "        return embedding\n",
        "\n",
        "    def embed_batch(self, texts: List[str], batch_size: int = 32) -> np.ndarray:\n",
        "        embeddings = self.model.encode(\n",
        "            texts,\n",
        "            batch_size=batch_size,\n",
        "            convert_to_numpy=True,\n",
        "            normalize_embeddings=True,\n",
        "            show_progress_bar=True\n",
        "        )\n",
        "        return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "F9-BGmAZYIBe"
      },
      "outputs": [],
      "source": [
        "#build vector database\n",
        "class VectorDatabase:\n",
        "    def __init__(self, dimension: int):\n",
        "        self.dimension = dimension\n",
        "        self.index = None\n",
        "        self.id_mapping = []\n",
        "\n",
        "    def build_index(self, embeddings: np.ndarray, ids: List[str]):\n",
        "        embeddings_normalized = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
        "        self.index = faiss.IndexFlatIP(self.dimension)\n",
        "        self.index.add(embeddings_normalized.astype('float32'))\n",
        "        self.id_mapping = ids\n",
        "        print(f\"Built FAISS index with {len(ids)} vectors\")\n",
        "\n",
        "    def search(self, query_embedding: np.ndarray, k: int = 5) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        query_normalized = query_embedding / np.linalg.norm(query_embedding)\n",
        "        query_normalized = query_normalized.reshape(1, -1).astype('float32')\n",
        "        similarities, indices = self.index.search(query_normalized, k)\n",
        "        return similarities[0], indices[0]\n",
        "\n",
        "    def save_index(self, path: str):\n",
        "        faiss.write_index(self.index, path)\n",
        "        print(f\"Index saved to {path}\")\n",
        "\n",
        "    def load_index(self, path: str):\n",
        "        self.index = faiss.read_index(path)\n",
        "        print(f\"Index loaded from {path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "vDPsE1PGYg7Q"
      },
      "outputs": [],
      "source": [
        "#the chatbot core\n",
        "#this is retrieve-based only for initial testing\n",
        "class VietnameseSignLanguageChatbot:\n",
        "    def __init__(self,\n",
        "                 json_path: str,\n",
        "                 model_name: str = \"dangvantuan/vietnamese-embedding\"):\n",
        "        print(\"Loading data...\")\n",
        "        self.data_handler = VietnameseSignLanguageData(json_path)\n",
        "        self.df = self.data_handler.load_data()\n",
        "        self.df = self.data_handler.prepare_data()\n",
        "\n",
        "        print(\"Initializing embedding model...\")\n",
        "        self.embedder = Embedder(model_name)\n",
        "        self.vector_db = None\n",
        "\n",
        "    def build_knowledge_base(self, batch_size: int = 32):\n",
        "\n",
        "        print(\"Building knowledge base...\")\n",
        "\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "        texts = self.df['searchable_text_normalized'].tolist()\n",
        "        embeddings = self.embedder.embed_batch(texts, batch_size=batch_size)\n",
        "\n",
        "        dimension = embeddings.shape[1]\n",
        "        self.vector_db = VectorDatabase(dimension)\n",
        "        self.vector_db.build_index(embeddings, self.df.index.tolist())\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "\n",
        "        print(\"Knowledge base built successfully!\")\n",
        "\n",
        "    #Handle user query\n",
        "    def query(self, user_query: str, top_k: int = 3, similarity_threshold: float = 0.5) -> List[Dict]:\n",
        "        normalized_query = self.data_handler.preprocess_text(user_query)\n",
        "        exact_matches = self.df[self.df['word_normalized'] == normalized_query]\n",
        "        if not exact_matches.empty:\n",
        "            return [{\n",
        "                'video_id': row['_id'],\n",
        "                'word': row['word'],\n",
        "                'description': row['description'],\n",
        "                'part_of_speech': row.get('tl', ''),\n",
        "                'similarity_score': 1.0,\n",
        "                'type': row.get('type', 0)\n",
        "            } for _, row in exact_matches.iterrows()]\n",
        "\n",
        "        # Fallback to semantic search\n",
        "        query_embedding = self.embedder.embed_text(normalized_query)\n",
        "        similarities, indices = self.vector_db.search(query_embedding, k=top_k)\n",
        "        results = []\n",
        "        for similarity, idx in zip(similarities, indices):\n",
        "            if similarity >= similarity_threshold:\n",
        "                row = self.df.iloc[idx]\n",
        "                result = {\n",
        "                    'video_id': row['_id'],\n",
        "                    'word': row['word'],\n",
        "                    'description': row['description'],\n",
        "                    'part_of_speech': row.get('tl', ''),\n",
        "                    'similarity_score': float(similarity),\n",
        "                    'type': row.get('type', 0)\n",
        "                }\n",
        "                results.append(result)\n",
        "\n",
        "        return results\n",
        "\n",
        "\n",
        "    def format_response(self, results: List[Dict]) -> str:\n",
        "        if not results:\n",
        "            return \"Xin lỗi, tôi không tìm thấy kết quả phù hợp. Vui lòng thử lại với từ khóa khác.\"\n",
        "\n",
        "        response = f\"Tìm thấy {len(results)} kết quả:\\n\\n\"\n",
        "        for i, result in enumerate(results, 1):\n",
        "            response += f\"--- Kết quả {i} ---\\n\"\n",
        "            response += f\"Từ: {result['word']}\\n\"\n",
        "            response += f\"ID Video: {result['video_id']}\\n\"\n",
        "            response += f\"Mô tả: {result['description']}\\n\"\n",
        "            response += f\"Loại từ: {result['part_of_speech']}\\n\"\n",
        "            response += f\"Độ tương đồng: {result['similarity_score']:.2%}\\n\\n\"\n",
        "\n",
        "        return response\n",
        "\n",
        "    def chat(self, user_query: str, top_k: int = 1) -> str:\n",
        "        results = self.query(user_query, top_k=top_k)\n",
        "        return self.format_response(results)\n",
        "\n",
        "    def save_knowledge_base(self, index_path: str, data_path: str):\n",
        "        self.vector_db.save_index(index_path)\n",
        "        self.df.to_pickle(data_path)\n",
        "        print(f\"Knowledge base saved to {index_path} and {data_path}\")\n",
        "\n",
        "    def load_knowledge_base(self, index_path: str, data_path: str):\n",
        "        self.df = pd.read_pickle(data_path)\n",
        "        sample_embedding = self.embedder.embed_text(\"test\")\n",
        "        dimension = len(sample_embedding)\n",
        "\n",
        "        self.vector_db = VectorDatabase(dimension)\n",
        "        self.vector_db.load_index(index_path)\n",
        "        self.vector_db.id_mapping = self.df.index.tolist()\n",
        "\n",
        "        print(\"Knowledge base loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210,
          "referenced_widgets": [
            "c30af4af764e44b791fed8fbe038af71",
            "c6f9256f783747c8a787d8da321fe378",
            "9d5db089a4c24e6b88f1701cde56d390",
            "05413ffb5aa14c2db78e99c420796146",
            "8f04c25713354038bf4044def5dea573",
            "05ed358a6fdf4980829969ea025a08b1",
            "93ba4fc1b1664b1397d1262a882af76a",
            "a14c332996aa4e32aecf0ce88fe50432",
            "b027aa3b827a4bfa9892dbd7594a90ba",
            "7d5194151ff8484580ed889dd55933c5",
            "6645118a35764538b2631020de01eceb"
          ]
        },
        "id": "9hxKEPf1ZRbu",
        "outputId": "bd03ee92-b034-489f-c2c5-91ebdf058305"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Loaded 4362 sign language entries\n",
            "Data preprocessing complete\n",
            "Initializing embedding model...\n",
            "Loading SentenceTransformer model: dangvantuan/vietnamese-embedding\n",
            "Model loaded successfully.\n",
            "Building knowledge base...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c30af4af764e44b791fed8fbe038af71",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/137 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Built FAISS index with 4362 vectors\n",
            "Knowledge base built successfully!\n"
          ]
        }
      ],
      "source": [
        "#Initialize chatbot\n",
        "chatbot = VietnameseSignLanguageChatbot(\n",
        "    json_path=\"/content/drive/MyDrive/VSL/data/VSL_DATA.json\",\n",
        "    model_name=\"dangvantuan/vietnamese-embedding\"\n",
        ")\n",
        "chatbot.build_knowledge_base(batch_size=32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mfupg5j3ZVed",
        "outputId": "904a3970-8384-4216-cc5f-0eb7283fb284"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nhập câu hỏi của bạn (hoặc 'quit' để thoát)\n",
            "Bạn: từ địa chỉ được diễn tả bằng ngôn ngữ kí hiệu như thế nào \n",
            "\n",
            "Chatbot:\n",
            "Tìm thấy 1 kết quả:\n",
            "\n",
            "--- Kết quả 1 ---\n",
            "Từ: nghĩa trang\n",
            "ID Video: W02371\n",
            "Mô tả: Nghĩa địa.\n",
            "Loại từ: Danh từ\n",
            "Độ tương đồng: 75.30%\n",
            "\n",
            "\n",
            "Bạn: từ địa chỉ được diễn tả như thế nào\n",
            "\n",
            "Chatbot:\n",
            "Tìm thấy 1 kết quả:\n",
            "\n",
            "--- Kết quả 1 ---\n",
            "Từ: nghĩa trang\n",
            "ID Video: W02371\n",
            "Mô tả: Nghĩa địa.\n",
            "Loại từ: Danh từ\n",
            "Độ tương đồng: 65.55%\n",
            "\n",
            "\n",
            "Bạn: cách diễn tả từ địa chỉ\n",
            "\n",
            "Chatbot:\n",
            "Tìm thấy 1 kết quả:\n",
            "\n",
            "--- Kết quả 1 ---\n",
            "Từ: nghĩa trang\n",
            "ID Video: W02371\n",
            "Mô tả: Nghĩa địa.\n",
            "Loại từ: Danh từ\n",
            "Độ tương đồng: 63.80%\n",
            "\n",
            "\n",
            "Bạn: quit\n",
            "Cảm ơn bạn đã sử dụng chatbot! Tạm biệt!\n"
          ]
        }
      ],
      "source": [
        "def interactive_chat(chatbot):\n",
        "    print(\"Nhập câu hỏi của bạn (hoặc 'quit' để thoát)\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"Bạn: \").strip()\n",
        "\n",
        "        if user_input.lower() in ['quit', 'exit', 'thoát']:\n",
        "            print(\"Cảm ơn bạn đã sử dụng chatbot! Tạm biệt!\")\n",
        "            break\n",
        "\n",
        "        if not user_input:\n",
        "            continue\n",
        "\n",
        "        response = chatbot.chat(user_input, top_k=1)\n",
        "        print(f\"\\nChatbot:\\n{response}\")\n",
        "\n",
        "interactive_chat(chatbot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6izlim23L4r"
      },
      "source": [
        "=> Base model does not work well, the chatbot can not capture the meaning in user query correctly and not function well in question answering.\n",
        "=> Currently checking on other models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GH0DHyD7kkd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05413ffb5aa14c2db78e99c420796146": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d5194151ff8484580ed889dd55933c5",
            "placeholder": "​",
            "style": "IPY_MODEL_6645118a35764538b2631020de01eceb",
            "value": " 137/137 [05:09&lt;00:00,  1.46it/s]"
          }
        },
        "05ed358a6fdf4980829969ea025a08b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6645118a35764538b2631020de01eceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d5194151ff8484580ed889dd55933c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f04c25713354038bf4044def5dea573": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93ba4fc1b1664b1397d1262a882af76a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d5db089a4c24e6b88f1701cde56d390": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a14c332996aa4e32aecf0ce88fe50432",
            "max": 137,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b027aa3b827a4bfa9892dbd7594a90ba",
            "value": 137
          }
        },
        "a14c332996aa4e32aecf0ce88fe50432": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b027aa3b827a4bfa9892dbd7594a90ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c30af4af764e44b791fed8fbe038af71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6f9256f783747c8a787d8da321fe378",
              "IPY_MODEL_9d5db089a4c24e6b88f1701cde56d390",
              "IPY_MODEL_05413ffb5aa14c2db78e99c420796146"
            ],
            "layout": "IPY_MODEL_8f04c25713354038bf4044def5dea573"
          }
        },
        "c6f9256f783747c8a787d8da321fe378": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05ed358a6fdf4980829969ea025a08b1",
            "placeholder": "​",
            "style": "IPY_MODEL_93ba4fc1b1664b1397d1262a882af76a",
            "value": "Batches: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
